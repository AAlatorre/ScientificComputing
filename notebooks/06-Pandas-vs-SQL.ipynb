{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas vs SQL\n",
    "Earlier in the semester, we examined how we can wrangle tables stored in a database with SQL. Here we see how Python can accomplish the same tasks, but from within the powerful Python environmnent and in a reproduceable fashion. \n",
    "\n",
    "In this exercise we revisit the analysis of the Seamap400 data of marine species observations - the same dataset we used in Exercise 2.3. While we are not covering this in much depth at all, these exercises should serve as a good introduction to what Pandas can do and how rows and columns are referenced in DataFrames.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the modules, we'll need Numpy as well for its datatypes\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the csv and checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Seamap400.csv file to a DataFrame\n",
    "dfSeamap = pd.read_csv('../Data/Seamap400.csv', index_col = 'ID')\n",
    "dfSeamap.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data types of the import\n",
    "dfSeamap.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the obs_date from generic 'object' data type to a datetime object\n",
    "dfSeamap['obs_date'] = pd.to_datetime(dfSeamap['obs_date'])\n",
    "print \"Earliest = \", dfSeamap['obs_date'].min()\n",
    "print \"Latest = \", dfSeamap['obs_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeamap.sp_common.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns from a dataFrame\n",
    "Selecting columns is analogous to the SQL `select ... from` clause, but the syntax in Pandas is a bit different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a single column\n",
    "Selecting a single column is easy as specifying the column name, either between brackets with the field name in quotes, or using the dot notation. (*The former is preferred, in case your field name is the the same as another property or method of a dataFrame.*)\n",
    "\n",
    "When only one column is selected, the object returned is actually not a  dataFrame, but a pandas **series** object, which is quite similar to a one-dimensional NumPy array. However, the Pandas series is limited to one dimension..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select just the sp_common field into a new view\n",
    "dfSelect = dfSeamap['sp_common']\n",
    "dfSelect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This also works\n",
    "commonNames = dfSeamap.sp_common\n",
    "type(commonNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The object returned is a series and we can get records from its index\n",
    "commonNames[:5] #Returns the first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What code would you use to get the last 5 records? (Replace the ???)\n",
    "commonNames[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting multiple columns\n",
    "Selecting multiple columns can be done by including a list of the column names. *Note the double set of brackets: the outer set is the syntax of the dataFrame object, and the inner set denotes the list of field names we want.*\n",
    "\n",
    "Here, the object returned resembles a dataFrame, not a series (since Pandas' series can only be one-dimension). However, in actuality, this is simply a **view** of the original dataFrame, not a new object - much like query views in SQL..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSelect = dfSeamap[['sp_common','sp_class']]\n",
    "type(dfSelect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting rows in a dataFrame\n",
    "Selecting rows, analogous to the `select...where` statement in SQL, is done by creating boolean masks of the criteria you want and then applying those masks. This can be done explicitily as two steps, or more commonly in a single, compount step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making our selection, let's examine how we can easily extract a list of valid options using the `unique` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the unique values in the 'sp_class' field.\n",
    "dfSeamap['sp_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting rows in two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Create the boolean mask\n",
    "theMask = dfSeamap['sp_class'] == 'Mammalia'\n",
    "theMask[2150:2156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Applying the mask to return only 'true' records\n",
    "dfMammals = dfSeamap[theMask]\n",
    "dfMammals.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting rows in one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the mammals and report all unique scientific names\n",
    "dfMammals = dfSeamap[dfSeamap['sp_class'] == 'Mammalia']\n",
    "dfMammals['scientific'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex row selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeamap['obs_date'].max()# > startDate).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select mammal records in the 2nd half of 2006\n",
    "mammalMask = dfSeamap['sp_class'] == 'Mammalia'\n",
    "\n",
    "#Create date objects for the start and end dates\n",
    "startDate = np.datetime64('2006-07-01')\n",
    "endDate = np.datetime64('2007-01-01')\n",
    "\n",
    "#Create the date masks\n",
    "startMask = (dfSeamap['obs_date'] >= startDate) \n",
    "endMask = (dfSeamap['obs_date'] < endDate)\n",
    "\n",
    "#Apply the masks, using the bitwise '&' to return rows where all masks are true\n",
    "dfSelect2 = dfSeamap[mammalMask & startMask & endMask]\n",
    "dfSelect2['scientific'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return rows matching a substring\n",
    "The `.str` function on a column allows us to use some string operations  on the values in that field.  Here we use the string `startswith` function to return all rows where the row's value starts with 'Delphin'. See https://pandas.pydata.org/pandas-docs/stable/text.html for other string operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows where the scientific name starts with \"Delphin\" \n",
    "dolphinMask = dfSeamap['scientific'].str.startswith('Delphin')\n",
    "dfDolphins = dfSeamap[dolphinMask]\n",
    "\n",
    "#Use the nunique function to just return the number \n",
    "#  of unique scientific names\n",
    "dfDolphins['scientific'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More complex queries with `apply` and  `lambda`\n",
    "For maximum flexibility, we can actually write our own functions to be applied to each value in a column (or multiple columns). This is done using the `apply` function to a dataFrame and then specifying the subcode we want to use with Python's `lambda` statement. (This seems fairly complex at first, but it actually somewhat straightforward -- and can be very useful...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask by searching each row for the string \"Whale\" and apply the mask\n",
    "# to list the scientific names of these records\n",
    "whaleMask = dfSeamap['sp_common'].apply(lambda x: 'Whale' in x)\n",
    "dfWhale = dfSeamap[whaleMask]\n",
    "dfWhale['scientific'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping/Aggregating data\n",
    "Pandas can aggregate data on values like SQL as well. We do this with the `groupby` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the observations by common name\n",
    "grpSpCommon = dfSeamap.groupby('sp_common')\n",
    "grpSpCommon['sp_common'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show *all* the summary stats with the dataFrame's `describe` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpSpCommon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining tables\n",
    "Also like SQL, pandas can join tables. Below we'll create two tables from our aggregated data: one will list the minimum of the latitude and longitude columns, and the second will list the maximum values. Then we'll join these two tables and compute the geographic extent of each species observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dataFrames of the minimum and then maximum of the lat and lng fields\n",
    "minCoords = grpSpCommon['latitude','longitude'].min()\n",
    "maxCoord = grpSpCommon['latitude','longitude'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at what is returned (for the min table)\n",
    "minCoords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Pandas 'merge' command to join the two tables\n",
    "sppExtent = pd.merge(left=minCoords,     #Specifies the left table\n",
    "                     right=maxCoord,     #Specifies the right table\n",
    "                     how = 'inner',      #Specifies the type of join\n",
    "                     left_index=True,    #Use the index of the left table as the join item\n",
    "                     right_index=True)   #Use the index of the right table as the join item\n",
    "#Have a look\n",
    "sppExtent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the columns to the values in the list provided\n",
    "sppExtent.columns = ['minX','minY','maxX','maxY']\n",
    "sppExtent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute two new columns as the difference between max and min\n",
    "sppExtent['XRange'] = sppExtent.maxX - sppExtent.minX\n",
    "sppExtent['YRange'] = sppExtent.maxY - sppExtent.minY\n",
    "sppExtent.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
